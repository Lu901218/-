日期:2025/6/10 | 講者:林俊良 | 題目:從智慧到製造:AI科技領域發展與未來

圖靈測試:
圖靈稱其為「模仿遊戲」（Imitation Game）。

實驗流程
一位詢問者提出問題。

問題會被傳送給：
一位人類回答者
一個機器（AI）
詢問者根據兩者的文字回答內容判斷誰是人、誰是機器。
溝通方式:
使用純文交流（無法聽到聲音或看到樣貌）。
目的是避免非語言因素（如聲音、外觀）影響判斷。
測試目標:
判斷機器是否具備與人類等同的智能。
如果詢問者無法準確區分哪一方是人類，則機器被認為通過圖靈測試。
核心概念:
不是測試機器是否有智慧，而是測試它是否能模仿人類的智慧行為。
關鍵在於模擬，而非真正的意識或理解。
意義與影響:
開啟了人工智慧領域的哲學與技術討論。
成為衡量「強人工智慧」的早期標準之一。

最終版本AlphaZero擁有更加強大的學習能力，可自我學習，在21天達到勝過中國頂尖棋士柯潔

機器學習需要人為特徵分類
深度學習則是由模型自己處理分類

CNN:從一快快圖像的方式來獲得對圖像的理解及區隔
RNN:具備處理有時間序列資料的能力，故可解讀不同階段累積的資料

LSTM（Long Short-Term Memory）是一種循環神經網路，基於RNN的架構多家輸入、忘記、輸出機制進行資訊選擇，以辨識應記憶、遺忘的資訊

生成式AI重點技術演進:
1. 傳統神經網路階段
1982年：RNN（循環神經網路）
  加入回饋機制，處理時間序列資料。
1997年：LSTM（長短期記憶模型）
  加入遺忘控制機制，有效記憶長距離資訊，改善RNN限制。
2. 序列模型演進
2014年：Seq2Seq 模型
  使用 Encoder-Decoder 結構與注意力機制處理序列輸入輸出。
2017年：Transformer
  完整使用注意力機制取代RNN，提升長距離學習能力與效率。
  成為後續大型語言模型（如GPT）的基礎。

生成模型技術發展:
2014年以前：Auto Encoder
  將圖片壓縮後再還原，訓練資料表徵學習。
2014年：GAN（生成對抗網路）
  透過生成器與判別器對抗訓練，生成與真實圖像相似的資料。
2015年：Diffusion Model（擴散模型）
  Step 1：加入雜訊
  Step 2：逐步還原圖像，提升生成品質與多樣性。
2022年：潛在擴散模型（Latent Diffusion）
  將Diffusion套用於AutoEncoder潛空間，提升效率與質量。

生成封抗網路
Generative Adversarial Networks (GANs)
GAN由兩假部分组成：生成器和判別器，生成器會建
立新的資料實例。而鑑別器根據真實資料對其進行評估

變分自動編碼器 Variational Autoencoders (VAEs)
與傳統的自動編碼器相同,VAE 架構有兩個部分:編碼器和解碼器。
傳統的 AE 模型將輸入映射到潛在空間向量 並根據該向量重建輸出

基於Transformer的模型 Transformer-based models
基於 Transformer 的模型代表了深 度學習的重大進步,特別是對於涉 及自然語言處理等順序資料的任務。
Transformer 同時處理整個序列, 使它們更有效率且更適合併行處理。 這種架構實現了從語言翻譯到文字 生成等各種應用的突破。最著名的 例子是GPT (Generative Pre- trained Transformer)系列,它展
示了生成類人文本的卓越能力。
